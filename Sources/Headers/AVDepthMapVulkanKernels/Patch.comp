#ifndef PATCH
#define PATCH

#include "color.comp"
#include "definitions.comp"
#include "DeviceCameraParams.comp"
#include "DevicePatchPattern.comp"
#include "Matrix.comp"
#include "SimStat.comp"

struct Patch
{
    vec3 p;     //< 3d point
    vec3 n;     //< normal
    vec3 x;     //< x axis
    vec3 y;     //< y axis
    float d;    //< pixel size
};

vec3 get3DPointForPixelAndFrontoParellePlaneRC(const DeviceCameraParams deviceCamParams, const vec2 pix, float fpPlaneDepth)
{
    const vec3 planep = deviceCamParams.C + deviceCamParams.ZVect * fpPlaneDepth;
    vec3 v = M3x3mulV2(deviceCamParams.iP, pix);
    v = normalize(v);
    return linePlaneIntersect(deviceCamParams.C, v, planep, deviceCamParams.ZVect);
}

vec3 get3DPointForPixelAndDepthFromRC(const DeviceCameraParams deviceCamParams, const vec2 pix, float depth)
{
    vec3 rpvIn = M3x3mulV2(deviceCamParams.iP, pix);
    vec3 rpvOut = normalize(rpvIn);
    return deviceCamParams.C + rpvOut * depth;
}

float computePixSize(const DeviceCameraParams deviceCamParams, const vec3 p)
{
    const vec2 rp = project3DPoint(deviceCamParams.P, p);
    const vec2 rp1 = rp + vec2(1.0f, 0.0f);

    vec3 refvect = M3x3mulV2(deviceCamParams.iP, rp1);
    refvect = normalize(refvect);
    return pointLineDistance3D(p, deviceCamParams.C, refvect);
}

void computeRotCSEpip(inout Patch pat,
    const DeviceCameraParams rcDeviceCamParams,
    const DeviceCameraParams tcDeviceCamParams)
{
    // Vector from the reference camera to the 3d point
    vec3 v1 = rcDeviceCamParams.C - pat.p;
    // Vector from the target camera to the 3d point
    vec3 v2 = tcDeviceCamParams.C - pat.p;
    v1 = normalize(v1);
    v2 = normalize(v2);

    // y has to be orthogonal to the epipolar plane
    // n has to be on the epipolar plane
    // x has to be on the epipolar plane

    pat.y = cross(v1, v2);
    pat.y = normalize(pat.y); // TODO: v1 & v2 are already normalized

    pat.n = (v1 + v2) / 2.0f; // IMPORTANT !!!
    pat.n = normalize(pat.n); // TODO: v1 & v2 are already normalized
    // ptch.n = sg_s_r.ZVect; //IMPORTANT !!!

    pat.x = cross(pat.y, pat.n);
    pat.x = normalize(pat.x);
}

void computeRcTcMipmapLevels(inout float out_rcMipmapLevel,
    inout float out_tcMipmapLevel,
    const float mipmapLevel,
    const DeviceCameraParams rcDeviceCamParams,
    const DeviceCameraParams tcDeviceCamParams,
    const vec2 rp0,
    const vec2 tp0,
    const vec3 p0)
{

    // get p0 depth from the R camera
    const float rcDepth = length(rcDeviceCamParams.C - p0);

    // get p0 depth from the T camera
    const float tcDepth = length(tcDeviceCamParams.C - p0);

    // get R p0 corresponding pixel + 1x
    const vec2 rp1 = rp0 + vec2(1.f, 0.f);

    // get T p0 corresponding pixel + 1x
    const vec2 tp1 = tp0 + vec2(1.f, 0.f);

    // get rp1 3d point
    vec3 rpv = M3x3mulV2(rcDeviceCamParams.iP, rp1);
    rpv = normalize(rpv);
    const vec3 prp1 = rcDeviceCamParams.C + rpv * rcDepth;

    // get tp1 3d point
    vec3 tpv = M3x3mulV2(tcDeviceCamParams.iP, tp1);
    tpv = normalize(tpv);
    const vec3 ptp1 = tcDeviceCamParams.C + tpv * tcDepth;

    // compute 3d distance between p0 and rp1 3d point
    const float rcDist = dist(p0, prp1);

    // compute 3d distance between p0 and tp1 3d point
    const float tcDist = dist(p0, ptp1);

    // compute Rc/Tc distance factor
    const float distFactor = rcDist / tcDist;

    // set output R and T mipmap level
    if(distFactor < 1.f)
    {
        // T camera has a lower resolution (1 Rc pixSize < 1 Tc pixSize)
        out_tcMipmapLevel = mipmapLevel - log2(1.f / distFactor);

        if(out_tcMipmapLevel < 0.f)
        {
            out_rcMipmapLevel = mipmapLevel + abs(out_tcMipmapLevel);
            out_tcMipmapLevel = 0.f;
        }
    }
    else
    {
        // T camera has a higher resolution (1 Rc pixSize > 1 Tc pixSize)
        out_rcMipmapLevel = mipmapLevel;
        out_tcMipmapLevel = mipmapLevel + log2(distFactor);
    }

}

/**
 * @brief Compute Normalized Cross-Correlation of a full square patch at given half-width.
 *
 * @tparam TInvertAndFilter invert and filter output similarity value
 *
 * @param[in] rcDeviceCameraParamsId the R camera parameters in device constant memory array
 * @param[in] tcDeviceCameraParamsId the T camera parameters in device constant memory array
 * @param[in] rcMipmapImage_tex the R camera mipmap image texture
 * @param[in] tcMipmapImage_tex the T camera mipmap image texture
 * @param[in] rcLevelWidth the R camera image width at given mipmapLevel
 * @param[in] rcLevelHeight the R camera image height at given mipmapLevel
 * @param[in] tcLevelWidth the T camera image width at given mipmapLevel
 * @param[in] tcLevelHeight the T camera image height at given mipmapLevel
 * @param[in] mipmapLevel the workflow current mipmap level (e.g. SGM=1.f, Refine=0.f)
 * @param[in] wsh the half-width of the patch
 * @param[in] invGammaC the inverted strength of grouping by color similarity
 * @param[in] invGammaP the inverted strength of grouping by proximity
 * @param[in] useConsistentScale enable consistent scale patch comparison
 * @param[in] tcLevelWidth the T camera image width at given mipmapLevel
 * @param[in] patch the input patch struct
 *
 * @return similarity value in range (-1.f, 0.f) or (0.f, 1.f) if TinvertAndFilter enabled
 *         special cases:
 *          -> infinite similarity value: 1
 *          -> invalid/uninitialized/masked similarity: CUDART_INF_F
 */
float compNCCby3DptsYK(const DeviceCameraParams rcDeviceCamParams,
    const DeviceCameraParams tcDeviceCamParams,
    const sampler2D rcMipmapImage_tex,
    const sampler2D tcMipmapImage_tex,
    const uint rcLevelWidth,
    const uint rcLevelHeight,
    const uint tcLevelWidth,
    const uint tcLevelHeight,
    const float mipmapLevel,
    const int wsh,
    const float invGammaC,
    const float invGammaP,
    const bool useConsistentScale,
    const Patch pat,
    const bool TInvertAndFilter)
{

    // get R and T image 2d coordinates from patch center 3d point
    const vec2 rp = project3DPoint(rcDeviceCamParams.P, pat.p);
    const vec2 tp = project3DPoint(tcDeviceCamParams.P, pat.p);

    // image 2d coordinates margin
    const float dd = wsh + 2.0f; // TODO: FACA

    // check R and T image 2d coordinates
    if((rp.x < dd) || (rp.x > float(rcLevelWidth  - 1) - dd) ||
        (tp.x < dd) || (tp.x > float(tcLevelWidth  - 1) - dd) ||
        (rp.y < dd) || (rp.y > float(rcLevelHeight - 1) - dd) ||
        (tp.y < dd) || (tp.y > float(tcLevelHeight - 1) - dd))
    {
        return 1. / 0.; // uninitialized
    }

    // compute inverse width / height
    // note: useful to compute normalized coordinates
    const float rcInvLevelWidth  = 1.f / float(rcLevelWidth);
    const float rcInvLevelHeight = 1.f / float(rcLevelHeight);
    const float tcInvLevelWidth  = 1.f / float(tcLevelWidth);
    const float tcInvLevelHeight = 1.f / float(tcLevelHeight);

    // initialize R and T mipmap image level at the given mipmap image level
    float rcMipmapLevel = mipmapLevel;
    float tcMipmapLevel = mipmapLevel;

    // update R and T mipmap image level in order to get consistent scale patch comparison
    if(useConsistentScale)
    {
        computeRcTcMipmapLevels(rcMipmapLevel, tcMipmapLevel, mipmapLevel, rcDeviceCamParams, tcDeviceCamParams, rp, tp, pat.p);
    }

    // create and initialize SimStat struct
    SimStat sst = SimStat(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0);

    // compute patch center color (CIELAB) at R and T mipmap image level
    const vec4 rcCenterColor = textureLod(rcMipmapImage_tex, vec2((rp.x + 0.5f) * rcInvLevelWidth, (rp.y + 0.5f) * rcInvLevelHeight), rcMipmapLevel);
    const vec4 tcCenterColor = textureLod(tcMipmapImage_tex, vec2((tp.x + 0.5f) * tcInvLevelWidth, (tp.y + 0.5f) * tcInvLevelHeight), tcMipmapLevel);

    // check the alpha values of the patch pixel center of the R and T cameras
    if(rcCenterColor.w < ALICEVISION_DEPTHMAP_RC_MIN_ALPHA || tcCenterColor.w < ALICEVISION_DEPTHMAP_TC_MIN_ALPHA)
    {
        return 1. / 0.; // masked
    }

    // compute patch (wsh*2+1)x(wsh*2+1)
    for(int yp = -wsh; yp <= wsh; ++yp)
    {
        for(int xp = -wsh; xp <= wsh; ++xp)
        {
            // get 3d point
            const vec3 p = pat.p + pat.x * float(pat.d * float(xp)) + pat.y * float(pat.d * float(yp));

            // get R and T image 2d coordinates from 3d point
            const vec2 rpc = project3DPoint(rcDeviceCamParams.P, p);
            const vec2 tpc = project3DPoint(tcDeviceCamParams.P, p);

            // get R and T image color (CIELAB) from 2d coordinates
            const vec4 rcPatchCoordColor = textureLod(rcMipmapImage_tex, vec2((rpc.x + 0.5f) * rcInvLevelWidth, (rpc.y + 0.5f) * rcInvLevelHeight), rcMipmapLevel);
            const vec4 tcPatchCoordColor = textureLod(tcMipmapImage_tex, vec2((tpc.x + 0.5f) * tcInvLevelWidth, (tpc.y + 0.5f) * tcInvLevelHeight), tcMipmapLevel);

            // compute weighting based on:
            // - color difference to the center pixel of the patch:
            //    - low value (close to 0) means that the color is different from the center pixel (ie. strongly supported surface)
            //    - high value (close to 1) means that the color is close the center pixel (ie. uniform color)
            // - distance in image to the center pixel of the patch:
            //    - low value (close to 0) means that the pixel is close to the center of the patch
            //    - high value (close to 1) means that the pixel is far from the center of the patch
            const float w = CostYKfromLab(xp, yp, rcCenterColor, rcPatchCoordColor, invGammaC, invGammaP) * CostYKfromLab(xp, yp, tcCenterColor, tcPatchCoordColor, invGammaC, invGammaP);

            // update simStat
            SimStat_update(sst, rcPatchCoordColor.x, tcPatchCoordColor.x, w);
        }
    }

    if(TInvertAndFilter)
    {
        // compute patch similarity
        const float fsim = SimStat_computeWSim(sst);

        // invert and filter similarity
        // apply sigmoid see: https://www.desmos.com/calculator/skmhf1gpyf
        // best similarity value was -1, worst was 0
        // best similarity value is 1, worst is still 0
        return sigmoid(0.0f, 1.0f, 0.7f, -0.7f, fsim);
    }

    // compute output patch similarity
    return SimStat_computeWSim(sst);
}

/**
 * @brief Compute Normalized Cross-Correlation of a patch with an user custom patch pattern.
 *
 * @tparam TInvertAndFilter invert and filter output similarity value
 *
 * @param[in] rcDeviceCameraParamsId the R camera parameters in device constant memory array
 * @param[in] tcDeviceCameraParamsId the T camera parameters in device constant memory array
 * @param[in] rcMipmapImage_tex the R camera mipmap image texture (aka sampler2D)
 * @param[in] tcMipmapImage_tex the T camera mipmap image texture (aka sampler2D)
 * @param[in] rcLevelWidth the R camera image width at given mipmapLevel
 * @param[in] rcLevelHeight the R camera image height at given mipmapLevel
 * @param[in] tcLevelWidth the T camera image width at given mipmapLevel
 * @param[in] tcLevelHeight the T camera image height at given mipmapLevel
 * @param[in] mipmapLevel the workflow current mipmap level (e.g. SGM=1.f, Refine=0.f)
 * @param[in] invGammaC the inverted strength of grouping by color similarity
 * @param[in] invGammaP the inverted strength of grouping by proximity
 * @param[in] useConsistentScale enable consistent scale patch comparison
 * @param[in] patch the input patch struct
 * @param[in] Whether the values should be inverted and filtered (maps to
 * template argument in CUDA)
 *
 * @return similarity value in range (-1.f, 0.f) or (0.f, 1.f) if TinvertAndFilter enabled
 *         special cases:
 *          -> infinite similarity value: 1
 *          -> invalid/uninitialized/masked similarity: CUDART_INF_F
 */
float compNCCby3DptsYK_customPatchPattern(const DeviceCameraParams rcDeviceCamParams,
    const DeviceCameraParams tcDeviceCamParams,
    const sampler2D rcMipmapImage_tex,
    const sampler2D tcMipmapImage_tex,
    const uint rcLevelWidth,
    const uint rcLevelHeight,
    const uint tcLevelWidth,
    const uint tcLevelHeight,
    const float mipmapLevel,
    const float invGammaC,
    const float invGammaP,
    const bool useConsistentScale,
    const Patch pat,
    const bool TInvertAndFilter,
    const DevicePatchPattern constantPatchPattern_d)
{

    // get R and T image 2d coordinates from patch center 3d point
    const vec2 rp = project3DPoint(rcDeviceCamParams.P, pat.p);
    const vec2 tp = project3DPoint(tcDeviceCamParams.P, pat.p);

    // image 2d coordinates margin
    const float dd = 2.f; // TODO: proper wsh handling

    // check R and T image 2d coordinates
    if((rp.x < dd) || (rp.x > float(rcLevelWidth  - 1) - dd) ||
        (tp.x < dd) || (tp.x > float(tcLevelWidth  - 1) - dd) ||
        (rp.y < dd) || (rp.y > float(rcLevelHeight - 1) - dd) ||
        (tp.y < dd) || (tp.y > float(tcLevelHeight - 1) - dd))
    {
        return 1. / 0.; // uninitialized
    }

    // compute inverse width / height
    // note: useful to compute normalized coordinates
    const float rcInvLevelWidth  = 1.f / float(rcLevelWidth);
    const float rcInvLevelHeight = 1.f / float(rcLevelHeight);
    const float tcInvLevelWidth  = 1.f / float(tcLevelWidth);
    const float tcInvLevelHeight = 1.f / float(tcLevelHeight);

    // get patch center pixel alpha at the given mipmap image level
    const float rcAlpha = textureLod(rcMipmapImage_tex, vec2((rp.x + 0.5f) * rcInvLevelWidth, (rp.y + 0.5f) * rcInvLevelHeight), mipmapLevel).w; // alpha only
    const float tcAlpha = textureLod(tcMipmapImage_tex, vec2((tp.x + 0.5f) * tcInvLevelWidth, (tp.y + 0.5f) * tcInvLevelHeight), mipmapLevel).w; // alpha only

    // check the alpha values of the patch pixel center of the R and T cameras
    if(rcAlpha < ALICEVISION_DEPTHMAP_RC_MIN_ALPHA || tcAlpha < ALICEVISION_DEPTHMAP_TC_MIN_ALPHA)
    {
        return 1. / 0.; // masked
    }

    // initialize R and T mipmap image level at the given mipmap image level
    float rcMipmapLevel = mipmapLevel;
    float tcMipmapLevel = mipmapLevel;

    // update R and T mipmap image level in order to get consistent scale patch comparison
    if(useConsistentScale)
    {
        computeRcTcMipmapLevels(rcMipmapLevel, tcMipmapLevel, mipmapLevel, rcDeviceCamParams, tcDeviceCamParams, rp, tp, pat.p);
    }

    // output similarity initialization
    float fsim = 0.f;
    float wsum = 0.f;

    for(int s = 0; s < constantPatchPattern_d.nbSubparts; ++s) {

        // create and initialize patch subpart SimStat
        SimStat sst = SimStat(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0);

        // get patch pattern subpart
        const DevicePatchPatternSubpart subpart = constantPatchPattern_d.subparts[s];

        // compute patch center color (CIELAB) at subpart level resolution
        const vec4 rcCenterColor = textureLod(rcMipmapImage_tex, vec2((rp.x + 0.5f) * rcInvLevelWidth, (rp.y + 0.5f) * rcInvLevelHeight), rcMipmapLevel + subpart.level);
        const vec4 tcCenterColor = textureLod(tcMipmapImage_tex, vec2((tp.x + 0.5f) * tcInvLevelWidth, (tp.y + 0.5f) * tcInvLevelHeight), tcMipmapLevel + subpart.level);

        if(subpart.isCircle) {
            for(int c = 0; c < subpart.nbCoordinates; ++c)
            {
                // get patch relative coordinates
                const vec2 relativeCoord = subpart.coordinates[c];

                // get 3d point from relative coordinates
                const vec3 p = pat.p + pat.x * float(pat.d * relativeCoord.x) + pat.y * float(pat.d * relativeCoord.y);

                // get R and T image 2d coordinates from 3d point
                const vec2 rpc = project3DPoint(rcDeviceCamParams.P, p);
                const vec2 tpc = project3DPoint(tcDeviceCamParams.P, p);

                // get R and T image color (CIELAB) from 2d coordinates
                const vec4 rcPatchCoordColor = textureLod(rcMipmapImage_tex, vec2((rpc.x + 0.5f) * rcInvLevelWidth, (rpc.y + 0.5f) * rcInvLevelHeight), rcMipmapLevel + subpart.level);
                const vec4 tcPatchCoordColor = textureLod(tcMipmapImage_tex, vec2((tpc.x + 0.5f) * tcInvLevelWidth, (tpc.y + 0.5f) * tcInvLevelHeight), tcMipmapLevel + subpart.level);

                // compute weighting based on color difference to the center pixel of the patch:
                // - low value (close to 0) means that the color is different from the center pixel (ie. strongly supported surface)
                // - high value (close to 1) means that the color is close the center pixel (ie. uniform color)
                const float w = CostYKfromLab(rcCenterColor, rcPatchCoordColor, invGammaC) * CostYKfromLab(tcCenterColor, tcPatchCoordColor, invGammaC);

                // update simStat
                SimStat_update(sst, rcPatchCoordColor.x, tcPatchCoordColor.x, w);
            }
        } else {
            for(int yp = -subpart.wsh; yp <= subpart.wsh; ++yp)
            {
                for (int xp = -subpart.wsh; xp <= subpart.wsh; ++xp)
                {
                    // get 3d point
                    const vec3 p = pat.p + pat.x * float(pat.d * float(xp) * subpart.downscale) + pat.y * float(pat.d * float(yp) * subpart.downscale);

                    // get R and T image 2d coordinates from 3d point
                    const vec2 rpc = project3DPoint(rcDeviceCamParams.P, p);
                    const vec2 tpc = project3DPoint(tcDeviceCamParams.P, p);

                    // get R and T image color (CIELAB) from 2d coordinates
                    const vec4 rcPatchCoordColor = textureLod(rcMipmapImage_tex, vec2((rpc.x + 0.5f) * rcInvLevelWidth, (rpc.y + 0.5f) * rcInvLevelHeight), rcMipmapLevel + subpart.level);
                    const vec4 tcPatchCoordColor = textureLod(tcMipmapImage_tex, vec2((tpc.x + 0.5f) * tcInvLevelWidth, (tpc.y + 0.5f) * tcInvLevelHeight), tcMipmapLevel + subpart.level);

                    // compute weighting based on:
                    // - color difference to the center pixel of the patch:
                    //    - low value (close to 0) means that the color is different from the center pixel (ie. strongly supported surface)
                    //    - high value (close to 1) means that the color is close the center pixel (ie. uniform color)
                    // - distance in image to the center pixel of the patch:
                    //    - low value (close to 0) means that the pixel is close to the center of the patch
                    //    - high value (close to 1) means that the pixel is far from the center of the patch
                    const float w = CostYKfromLab(xp, yp, rcCenterColor, rcPatchCoordColor, invGammaC, invGammaP) * CostYKfromLab(xp, yp, tcCenterColor, tcPatchCoordColor, invGammaC, invGammaP);

                    SimStat_update(sst, rcPatchCoordColor.x, tcPatchCoordColor.x, w);
                }
            }
        }

        // compute patch subpart similarity
        const float fsimSubpart = SimStat_computeWSim(sst);

        // similarity value in range (-1.f, 0.f) or invalid
        if(fsimSubpart < 0.f)
        {
            // add patch pattern subpart similarity to patch similarity
            if(TInvertAndFilter)
            {
                // invert and filter similarity
                // apply sigmoid see: https://www.desmos.com/calculator/skmhf1gpyf
                // best similarity value was -1, worst was 0
                // best similarity value is 1, worst is still 0
                const float fsimInverted = sigmoid(0.0f, 1.0f, 0.7f, -0.7f, fsimSubpart);
                fsim += fsimInverted * subpart.weight;

            }
            else
            {
                // weight and add similarity
                fsim += fsimSubpart * subpart.weight;
            }

            // sum subpart weight
            wsum += subpart.weight;
        }
    }

    // invalid patch similarity
    if(wsum == 0.f)
    {
        return 1. / 0.;
    }

    if(TInvertAndFilter)
    {
        // for now, we do not average
        return fsim;
    }

    // output average similarity
    return (fsim / wsum);

}

#endif